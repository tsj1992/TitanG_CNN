{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(\"X_60.pickle\", \"rb\"))\n",
    "Y = pickle.load(open(\"Y_60.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Specifing run configurations and regularization constants. These are used to tweak the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CONFIGURATIONS\n",
    "TEST = 3\n",
    "CNN_ACT_F = \"relu\"\n",
    "DNS_ACT_F = \"tanh\"\n",
    "ARCH = f\"CNN(64,128,256)_{CNN_ACT_F}_DENSE(128,64,32,12)_{DNS_ACT_F}\"\n",
    "IMG_SIZE = 60\n",
    "N_SPLIT = 5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 50\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "\n",
    "# REGULARIZATIONS\n",
    "DROPOUT_RATE = 0.4\n",
    "LAMBDA_1 = 1e-5\n",
    "LAMBDA_2 = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating the report name for the corresponding tweak of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 - CNN(64,128,256)_relu_DENSE(128,64,32,12)_tanh - 60px_30e_50bs_10vs_REG_40do_10L1_10L2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPORT_NAME = f\"{TEST} - {ARCH} - {IMG_SIZE}px_{EPOCHS}e_{BATCH_SIZE}bs_{int(VAL_SPLIT*100)}vs_REG_{int(DROPOUT_RATE*100)}do_{int(LAMBDA_1*1000000)}L1_{int(LAMBDA_2*1000000)}L2\"\n",
    "REPORT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing tensorflow-gpu and other related libs and classes. Tensorboard is used to see live tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"NN_GA_CNN_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{MODEL_NAME}\")\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), input_shape=(IMG_SIZE,IMG_SIZE,1)))  # input shape is IMG_SIZExIMG_SIZEx1\n",
    "#     model.add(BatchNormalization(axis=3))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(128, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(rate=DROPOUT_RATE))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128))\n",
    "    model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating folder for saving reports of the model executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('reports'):\n",
    "    os.makedirs('reports')\n",
    "\n",
    "file = open(f\"reports/{REPORT_NAME}.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Designed the 5-fold cross validation training and test with specific validation split. Final accuracy is averaged by the accuracies of the separate 5 folds. Time taken for the execution is also measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# initializing variables for kFold run and average accuracy\n",
    "current_fold = 0\n",
    "sum_acc = 0\n",
    "avg_acc = 0\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "for train_index, test_index in KFold(N_SPLIT).split(X):\n",
    "    current_fold += 1\n",
    "    \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    \n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT, callbacks=[tensorboard])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"\\nFOLD-{current_fold}: Loss={val_loss} , Accuracy={val_acc}\\n\")\n",
    "    \n",
    "    sum_acc += val_acc \n",
    "    file.write(f\"{current_fold}-FOLD | Loss={round(val_loss,4)},\\tAccuracy={round(val_acc,4)},\\tAverage_Accuracy={round(sum_acc/current_fold,4)}\\n\")\n",
    "    \n",
    "    if(current_fold == N_SPLIT):\n",
    "        avg_acc = round(sum_acc/current_fold,4)\n",
    "    \n",
    "\n",
    "avg_acc_line = f\"\\nAverage Accuracy : {round(avg_acc,4)}\"\n",
    "\n",
    "end = time.process_time()\n",
    "time_taken = f\"\\nExecutionb Time\\t : {round(end-start,4)}s\"\n",
    "\n",
    "print(avg_acc_line)\n",
    "print(time_taken)\n",
    "\n",
    "file.write(avg_acc_line)\n",
    "file.write(time_taken)\n",
    "    \n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow-gpu-1-13)",
   "language": "python",
   "name": "tensorflow-gpu-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
