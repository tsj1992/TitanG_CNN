{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Specifing run configurations and regularization constants. These are used to tweak the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CONFIGURATIONS\n",
    "TEST = 21\n",
    "CNN_ACT_F = \"relu\"\n",
    "DNS_ACT_F = \"tanh\"\n",
    "ARCH = f\"CNN(64,128,256)_{CNN_ACT_F}_DENSE(128,64,32,12)_{DNS_ACT_F}\"\n",
    "IMG_SIZE = 70\n",
    "N_SPLIT = 5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 50\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "LR = 0.0095\n",
    "MM = 0.9\n",
    "\n",
    "\n",
    "# REGULARIZATIONS\n",
    "DROPOUT_RATE = 0.5\n",
    "LAMBDA_1 = 1e-5\n",
    "LAMBDA_2 = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(f\"X_{IMG_SIZE}.pickle\", \"rb\"))\n",
    "Y = pickle.load(open(f\"Y_{IMG_SIZE}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating the report name for the corresponding tweak of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_1 = f\"{TEST} - {ARCH} - {IMG_SIZE}px_{EPOCHS}e_{BATCH_SIZE}bs_{int(VAL_SPLIT*100)}vs_REG_{int(DROPOUT_RATE*100)}do_{int(LAMBDA_1*1000000)}L1_{int(LAMBDA_2*1000000)}L2\"\n",
    "SET_2 = f\"{TEST} - {IMG_SIZE}px_{EPOCHS}e_{BATCH_SIZE}bs_{int(VAL_SPLIT*100)}vs_REG_{int(DROPOUT_RATE*100)}do_{int(LAMBDA_1*1000000)}L1_{int(LAMBDA_2*1000000)}L2_{int(LR*10000)}LR_{int(MM*100)}M\"\n",
    "REPORT_NAME = SET_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing tensorflow-gpu and other related libs and classes. Tensorboard is used to see live tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"NN_GA_CNN_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{MODEL_NAME}\")\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), input_shape=(IMG_SIZE,IMG_SIZE,1)))  # input shape is IMG_SIZExIMG_SIZEx1\n",
    "#     model.add(BatchNormalization(axis=3))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(128, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(rate=DROPOUT_RATE))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128))\n",
    "    model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(lr=LR, momentum=MM, nesterov=False)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating folder for saving reports of the model executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('reports'):\n",
    "    os.makedirs('reports')\n",
    "\n",
    "file = open(f\"reports/{REPORT_NAME}.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Designed the 5-fold cross validation training and test with specific validation split. Final accuracy is averaged by the accuracies of the separate 5 folds. Time taken for the execution is also measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 2.4452 - acc: 0.1418 - val_loss: 2.4269 - val_acc: 0.1605\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4029 - acc: 0.1515 - val_loss: 2.3819 - val_acc: 0.1658\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3693 - acc: 0.1550 - val_loss: 2.4054 - val_acc: 0.1658\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.3482 - acc: 0.1754 - val_loss: 2.3505 - val_acc: 0.1553\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3593 - acc: 0.1626 - val_loss: 2.4371 - val_acc: 0.1447\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3292 - acc: 0.1827 - val_loss: 2.3143 - val_acc: 0.2105\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.2684 - acc: 0.2132 - val_loss: 2.2904 - val_acc: 0.1947\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.2418 - acc: 0.2260 - val_loss: 2.3271 - val_acc: 0.17896\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.1587 - acc: 0.2620 - val_loss: 2.4115 - val_acc: 0.1763\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.1023 - acc: 0.2804 - val_loss: 2.2115 - val_acc: 0.2447\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.9764 - acc: 0.3289 - val_loss: 2.2402 - val_acc: 0.2579\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.8607 - acc: 0.3602 - val_loss: 1.9450 - val_acc: 0.3553\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.6845 - acc: 0.4360 - val_loss: 1.8890 - val_acc: 0.3605\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.5413 - acc: 0.4927 - val_loss: 1.8270 - val_acc: 0.3868\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.3716 - acc: 0.5465 - val_loss: 1.7193 - val_acc: 0.4368\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.2644 - acc: 0.5822 - val_loss: 1.5557 - val_acc: 0.4500\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 1.0824 - acc: 0.6503 - val_loss: 1.6265 - val_acc: 0.4263\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.0196 - acc: 0.6649 - val_loss: 1.5673 - val_acc: 0.5211\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.8471 - acc: 0.7345 - val_loss: 1.5082 - val_acc: 0.4895\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.7154 - acc: 0.7772 - val_loss: 1.5113 - val_acc: 0.5105\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.6073 - acc: 0.8152 - val_loss: 1.5300 - val_acc: 0.5289\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.5280 - acc: 0.8424 - val_loss: 1.5791 - val_acc: 0.5237\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.3793 - acc: 0.9003 - val_loss: 1.4947 - val_acc: 0.5684\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.2610 - acc: 0.9459 - val_loss: 1.6615 - val_acc: 0.4947\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1963 - acc: 0.9646 - val_loss: 1.6522 - val_acc: 0.5289\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1303 - acc: 0.9819 - val_loss: 1.5947 - val_acc: 0.5500\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0853 - acc: 0.9980 - val_loss: 1.6101 - val_acc: 0.5763.0850 - acc: 0.9\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0615 - acc: 0.9988 - val_loss: 1.6173 - val_acc: 0.5658\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0484 - acc: 0.9997 - val_loss: 1.6890 - val_acc: 0.5658\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0420 - acc: 0.9997 - val_loss: 1.6958 - val_acc: 0.5737\n",
      "950/950 [==============================] - 1s 1ms/sample - loss: 1.5870 - acc: 0.5737\n",
      "\n",
      "FOLD-1: Loss=1.587031267065751 , Accuracy=0.5736842155456543\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.4504 - acc: 0.1319 - val_loss: 2.4405 - val_acc: 0.1395\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.4216 - acc: 0.1404 - val_loss: 2.4067 - val_acc: 0.1579\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3782 - acc: 0.1602 - val_loss: 2.3670 - val_acc: 0.1632\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3389 - acc: 0.1763 - val_loss: 2.3510 - val_acc: 0.1921loss: - ETA: 2s - los\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3256 - acc: 0.1871 - val_loss: 2.3164 - val_acc: 0.2079\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2892 - acc: 0.1906 - val_loss: 2.5104 - val_acc: 0.1474\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2741 - acc: 0.2096 - val_loss: 2.2971 - val_acc: 0.2026\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.1834 - acc: 0.2535 - val_loss: 2.3108 - val_acc: 0.1947\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.1472 - acc: 0.2596 - val_loss: 2.2854 - val_acc: 0.1947\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.9872 - acc: 0.3272 - val_loss: 2.0719 - val_acc: 0.3105\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.8683 - acc: 0.3734 - val_loss: 1.9687 - val_acc: 0.3658\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.6567 - acc: 0.4480 - val_loss: 1.8718 - val_acc: 0.3579\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.4816 - acc: 0.5137 - val_loss: 1.8099 - val_acc: 0.4026\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.4755 - acc: 0.4991 - val_loss: 1.6780 - val_acc: 0.4342\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.2263 - acc: 0.6082 - val_loss: 1.8780 - val_acc: 0.3737\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.1466 - acc: 0.6202 - val_loss: 1.8912 - val_acc: 0.3842\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.9995 - acc: 0.6798 - val_loss: 1.4311 - val_acc: 0.5184\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.8333 - acc: 0.7336 - val_loss: 1.4226 - val_acc: 0.5421\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.7339 - acc: 0.7737 - val_loss: 1.7484 - val_acc: 0.4447\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.6512 - acc: 0.7904 - val_loss: 1.4628 - val_acc: 0.5447\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.4773 - acc: 0.8702 - val_loss: 1.4536 - val_acc: 0.5395\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.3804 - acc: 0.8994 - val_loss: 1.7031 - val_acc: 0.5079\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.3264 - acc: 0.9193 - val_loss: 1.6571 - val_acc: 0.5079\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.2471 - acc: 0.9398 - val_loss: 1.5865 - val_acc: 0.5368\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1656 - acc: 0.9699 - val_loss: 1.6166 - val_acc: 0.5368\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1097 - acc: 0.9877 - val_loss: 1.6060 - val_acc: 0.5237\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0687 - acc: 0.9965 - val_loss: 1.6146 - val_acc: 0.5500\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0547 - acc: 0.9988 - val_loss: 1.6637 - val_acc: 0.5447\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0481 - acc: 0.9997 - val_loss: 1.6570 - val_acc: 0.5447\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0396 - acc: 1.0000 - val_loss: 1.6883 - val_acc: 0.5447\n",
      "950/950 [==============================] - 1s 750us/sample - loss: 1.5392 - acc: 0.6095\n",
      "\n",
      "FOLD-2: Loss=1.539151146788346 , Accuracy=0.609473705291748\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.4461 - acc: 0.1319 - val_loss: 2.4453 - val_acc: 0.1395\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4167 - acc: 0.1518 - val_loss: 2.4073 - val_acc: 0.1632\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.3765 - acc: 0.1512 - val_loss: 2.3727 - val_acc: 0.1684\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3733 - acc: 0.1544 - val_loss: 2.4158 - val_acc: 0.1579\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3591 - acc: 0.1594 - val_loss: 2.4147 - val_acc: 0.1605\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3079 - acc: 0.2003 - val_loss: 2.3475 - val_acc: 0.1711\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2738 - acc: 0.2102 - val_loss: 2.3316 - val_acc: 0.2132\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2185 - acc: 0.2427 - val_loss: 2.2233 - val_acc: 0.2474\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.1485 - acc: 0.2655 - val_loss: 2.2072 - val_acc: 0.2684\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.0733 - acc: 0.2950 - val_loss: 2.1327 - val_acc: 0.2868\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.9954 - acc: 0.3196 - val_loss: 2.1251 - val_acc: 0.3000\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.8777 - acc: 0.3640 - val_loss: 2.0594 - val_acc: 0.3184\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.7330 - acc: 0.4102 - val_loss: 1.8933 - val_acc: 0.3737\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.5664 - acc: 0.4819 - val_loss: 1.7548 - val_acc: 0.4421\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.4044 - acc: 0.5404 - val_loss: 1.7779 - val_acc: 0.4342\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.2874 - acc: 0.5719 - val_loss: 1.6247 - val_acc: 0.4526\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.1605 - acc: 0.6161 - val_loss: 1.8721 - val_acc: 0.4289\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.9942 - acc: 0.6719 - val_loss: 1.4683 - val_acc: 0.5158\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.8358 - acc: 0.7351 - val_loss: 1.4510 - val_acc: 0.5237\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.7298 - acc: 0.7684 - val_loss: 1.4785 - val_acc: 0.5316\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.6589 - acc: 0.7959 - val_loss: 1.6041 - val_acc: 0.5000\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 0.5624 - acc: 0.8319 - val_loss: 1.6566 - val_acc: 0.5132\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.4091 - acc: 0.8889 - val_loss: 1.5266 - val_acc: 0.5263\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.3148 - acc: 0.9199 - val_loss: 1.5604 - val_acc: 0.5316\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1875 - acc: 0.9673 - val_loss: 1.6675 - val_acc: 0.5211\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1779 - acc: 0.9725 - val_loss: 1.6755 - val_acc: 0.5316\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0971 - acc: 0.9939 - val_loss: 1.6618 - val_acc: 0.5763\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0654 - acc: 0.9980 - val_loss: 1.6542 - val_acc: 0.5474\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0517 - acc: 0.9988 - val_loss: 1.6816 - val_acc: 0.5553\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0442 - acc: 0.9994 - val_loss: 1.6955 - val_acc: 0.5605\n",
      "950/950 [==============================] - 1s 1ms/sample - loss: 1.6032 - acc: 0.5632\n",
      "\n",
      "FOLD-3: Loss=1.6031758737564088 , Accuracy=0.5631579160690308\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 2.4535 - acc: 0.1257 - val_loss: 2.4458 - val_acc: 0.1605\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.4143 - acc: 0.1544 - val_loss: 2.4018 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3625 - acc: 0.1678 - val_loss: 2.4038 - val_acc: 0.1763\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3343 - acc: 0.1833 - val_loss: 2.3523 - val_acc: 0.1368\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2904 - acc: 0.2085 - val_loss: 2.3031 - val_acc: 0.2263\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2551 - acc: 0.2228 - val_loss: 2.2808 - val_acc: 0.2237\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.1847 - acc: 0.2547 - val_loss: 2.2152 - val_acc: 0.2711\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.0819 - acc: 0.3023 - val_loss: 2.1860 - val_acc: 0.2684\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 1.9865 - acc: 0.3330 - val_loss: 2.0677 - val_acc: 0.3053\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 11s 3ms/sample - loss: 1.7861 - acc: 0.4091 - val_loss: 1.8906 - val_acc: 0.3737\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 1.6807 - acc: 0.4506 - val_loss: 1.8046 - val_acc: 0.4000\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.5004 - acc: 0.5020 - val_loss: 1.7224 - val_acc: 0.4053\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 1.3684 - acc: 0.5532 - val_loss: 1.7949 - val_acc: 0.4000\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.2887 - acc: 0.5795 - val_loss: 1.9363 - val_acc: 0.3684\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.1121 - acc: 0.6418 - val_loss: 1.8147 - val_acc: 0.4079\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 1.0555 - acc: 0.6594 - val_loss: 1.4893 - val_acc: 0.4763\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.8365 - acc: 0.7371 - val_loss: 1.5121 - val_acc: 0.5000\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.6926 - acc: 0.7857 - val_loss: 1.5147 - val_acc: 0.5237\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.6202 - acc: 0.8140 - val_loss: 1.6388 - val_acc: 0.4921\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.4883 - acc: 0.8596 - val_loss: 1.6787 - val_acc: 0.4895\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.3860 - acc: 0.9012 - val_loss: 1.6427 - val_acc: 0.5105\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.2950 - acc: 0.9284 - val_loss: 1.6098 - val_acc: 0.5342\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.2643 - acc: 0.9360 - val_loss: 1.7128 - val_acc: 0.5316\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1595 - acc: 0.9754 - val_loss: 1.7605 - val_acc: 0.5132\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.1129 - acc: 0.9854 - val_loss: 1.6866 - val_acc: 0.5289\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0755 - acc: 0.9947 - val_loss: 1.7285 - val_acc: 0.5289\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0572 - acc: 0.9977 - val_loss: 1.7424 - val_acc: 0.5289\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0475 - acc: 0.9994 - val_loss: 1.7522 - val_acc: 0.5342\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0421 - acc: 0.9994 - val_loss: 1.7791 - val_acc: 0.5263\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0390 - acc: 0.9994 - val_loss: 1.7970 - val_acc: 0.5395\n",
      "950/950 [==============================] - 1s 933us/sample - loss: 1.6557 - acc: 0.5674\n",
      "\n",
      "FOLD-4: Loss=1.655667580052426 , Accuracy=0.5673684477806091\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 12s 4ms/sample - loss: 2.4518 - acc: 0.1319 - val_loss: 2.4017 - val_acc: 0.1842\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 2.4189 - acc: 0.1442 - val_loss: 2.3731 - val_acc: 0.1632\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.3773 - acc: 0.1515 - val_loss: 2.3346 - val_acc: 0.1526\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.3522 - acc: 0.1696 - val_loss: 2.3396 - val_acc: 0.1921\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.3416 - acc: 0.1880 - val_loss: 2.3125 - val_acc: 0.1974\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.2934 - acc: 0.2032 - val_loss: 2.3001 - val_acc: 0.2211\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.2526 - acc: 0.2213 - val_loss: 2.2651 - val_acc: 0.2000\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.2290 - acc: 0.2354 - val_loss: 2.2615 - val_acc: 0.2079\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.1293 - acc: 0.2772 - val_loss: 2.2798 - val_acc: 0.2184\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 2.0269 - acc: 0.3240 - val_loss: 2.0592 - val_acc: 0.3079\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.9028 - acc: 0.3500 - val_loss: 1.9679 - val_acc: 0.3211\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 1.6817 - acc: 0.4468 - val_loss: 1.7792 - val_acc: 0.3921\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.5617 - acc: 0.4857 - val_loss: 1.6892 - val_acc: 0.4158\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.3908 - acc: 0.5342 - val_loss: 1.8757 - val_acc: 0.3763\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.2442 - acc: 0.5895 - val_loss: 1.4796 - val_acc: 0.5000\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 1.0991 - acc: 0.6374 - val_loss: 1.5529 - val_acc: 0.4789\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.9703 - acc: 0.6980 - val_loss: 1.5956 - val_acc: 0.4737\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 9s 3ms/sample - loss: 0.8346 - acc: 0.7333 - val_loss: 1.3554 - val_acc: 0.5368\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.7124 - acc: 0.7769 - val_loss: 1.4104 - val_acc: 0.5368\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.6656 - acc: 0.7924 - val_loss: 1.4912 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.5339 - acc: 0.8401 - val_loss: 1.4248 - val_acc: 0.5079\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.4283 - acc: 0.8789 - val_loss: 1.3936 - val_acc: 0.5579\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.2841 - acc: 0.9371 - val_loss: 1.4377 - val_acc: 0.5395\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.2213 - acc: 0.9535 - val_loss: 1.3894 - val_acc: 0.5211\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 0.1573 - acc: 0.9743 - val_loss: 1.4593 - val_acc: 0.5737\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.0992 - acc: 0.9918 - val_loss: 1.4889 - val_acc: 0.5474\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.0800 - acc: 0.9950 - val_loss: 1.6554 - val_acc: 0.5447\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.0619 - acc: 0.9974 - val_loss: 1.5582 - val_acc: 0.5632\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.0492 - acc: 0.9991 - val_loss: 1.5156 - val_acc: 0.5763\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 10s 3ms/sample - loss: 0.0429 - acc: 0.9991 - val_loss: 1.5383 - val_acc: 0.5842\n",
      "950/950 [==============================] - 2s 2ms/sample - loss: 1.6067 - acc: 0.5937\n",
      "\n",
      "FOLD-5: Loss=1.6067200207710266 , Accuracy=0.593684196472168\n",
      "\n",
      "\n",
      "Average Accuracy : 0.5815\n",
      "\n",
      "Execution Time\t : 1827.25s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# initializing variables for kFold run and average accuracy\n",
    "current_fold = 0\n",
    "sum_acc = 0\n",
    "avg_acc = 0\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "for train_index, test_index in KFold(N_SPLIT).split(X):\n",
    "    current_fold += 1\n",
    "    \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    \n",
    "#     earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT, callbacks=[tensorboard])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"\\nFOLD-{current_fold}: Loss={val_loss} , Accuracy={val_acc}\\n\")\n",
    "    \n",
    "    sum_acc += val_acc \n",
    "    file.write(f\"{current_fold}-FOLD | Loss={round(val_loss,4)},\\tAccuracy={round(val_acc,4)},\\tAverage_Accuracy={round(sum_acc/current_fold,4)}\\n\")\n",
    "    \n",
    "    if(current_fold == N_SPLIT):\n",
    "        avg_acc = round(sum_acc/current_fold,4)\n",
    "    \n",
    "\n",
    "avg_acc_line = f\"\\nAverage Accuracy : {round(avg_acc,4)}\"\n",
    "\n",
    "end = time.process_time()\n",
    "time_taken = f\"\\nExecution Time\\t : {round(end-start,4)}s\"\n",
    "\n",
    "print(avg_acc_line)\n",
    "print(time_taken)\n",
    "\n",
    "file.write(avg_acc_line)\n",
    "file.write(time_taken)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{REPORT_NAME}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 68, 68, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 68, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,560,172\n",
      "Trainable params: 1,560,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To reset GPU memory after model training. But seems this doesn't work. Always need to restart the kernel and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow-gpu-1-13)",
   "language": "python",
   "name": "tensorflow-gpu-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
