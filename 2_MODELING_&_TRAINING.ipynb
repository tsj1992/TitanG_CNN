{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Specifing run configurations and regularization constants. These are used to tweak the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CONFIGURATIONS\n",
    "TEST = 2\n",
    "CNN_ACT_F = \"relu\"\n",
    "DNS_ACT_F = \"tanh\"\n",
    "ARCH = f\"CNN(64,128,256)_{CNN_ACT_F}_DENSE(128,64,32,12)_{DNS_ACT_F}\"\n",
    "IMG_SIZE = 60\n",
    "N_SPLIT = 5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 250\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "\n",
    "# REGULARIZATIONS\n",
    "DROPOUT_RATE = 0.4\n",
    "LAMBDA_1 = 1e-5\n",
    "LAMBDA_2 = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(f\"X_{IMG_SIZE}.pickle\", \"rb\"))\n",
    "Y = pickle.load(open(f\"Y_{IMG_SIZE}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating the report name for the corresponding tweak of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 - CNN(64,128,256)_relu_DENSE(128,64,32,12)_tanh - 60px_30e_250bs_10vs_REG_40do_10L1_10L2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPORT_NAME = f\"{TEST} - {ARCH} - {IMG_SIZE}px_{EPOCHS}e_{BATCH_SIZE}bs_{int(VAL_SPLIT*100)}vs_REG_{int(DROPOUT_RATE*100)}do_{int(LAMBDA_1*1000000)}L1_{int(LAMBDA_2*1000000)}L2\"\n",
    "REPORT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing tensorflow-gpu and other related libs and classes. Tensorboard is used to see live tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"NN_GA_CNN_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{MODEL_NAME}\")\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), input_shape=(IMG_SIZE,IMG_SIZE,1)))  # input shape is IMG_SIZExIMG_SIZEx1\n",
    "#     model.add(BatchNormalization(axis=3))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(128, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(rate=DROPOUT_RATE))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128))\n",
    "    model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating folder for saving reports of the model executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('reports'):\n",
    "    os.makedirs('reports')\n",
    "\n",
    "file = open(f\"reports/{REPORT_NAME}.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Designed the 5-fold cross validation training and test with specific validation split. Final accuracy is averaged by the accuracies of the separate 5 folds. Time taken for the execution is also measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 11s 3ms/sample - loss: 2.5697 - acc: 0.1234 - val_loss: 2.5529 - val_acc: 0.1132\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5319 - acc: 0.1251 - val_loss: 2.5478 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5236 - acc: 0.1386 - val_loss: 2.5390 - val_acc: 0.1395\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5192 - acc: 0.1386 - val_loss: 2.5351 - val_acc: 0.1368\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5165 - acc: 0.1547 - val_loss: 2.5323 - val_acc: 0.1395\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5118 - acc: 0.1386 - val_loss: 2.5273 - val_acc: 0.1395\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5045 - acc: 0.1474 - val_loss: 2.5243 - val_acc: 0.1289\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4965 - acc: 0.1582 - val_loss: 2.5142 - val_acc: 0.1342\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4876 - acc: 0.1655 - val_loss: 2.5056 - val_acc: 0.1474\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4785 - acc: 0.1640 - val_loss: 2.5006 - val_acc: 0.1289\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4620 - acc: 0.1599 - val_loss: 2.4812 - val_acc: 0.1342\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4503 - acc: 0.1611 - val_loss: 2.4759 - val_acc: 0.1342\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4389 - acc: 0.1754 - val_loss: 2.4634 - val_acc: 0.1395\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4246 - acc: 0.1801 - val_loss: 2.4497 - val_acc: 0.1237\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4162 - acc: 0.1830 - val_loss: 2.4532 - val_acc: 0.1474\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4058 - acc: 0.1851 - val_loss: 2.4358 - val_acc: 0.1474\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.3922 - acc: 0.1942 - val_loss: 2.4195 - val_acc: 0.1658\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3943 - acc: 0.1924 - val_loss: 2.4266 - val_acc: 0.1526\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3796 - acc: 0.2035 - val_loss: 2.4095 - val_acc: 0.1895\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3567 - acc: 0.2140 - val_loss: 2.3883 - val_acc: 0.1763\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3348 - acc: 0.2319 - val_loss: 2.3670 - val_acc: 0.1789\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3241 - acc: 0.2298 - val_loss: 2.3504 - val_acc: 0.2105\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3088 - acc: 0.2512 - val_loss: 2.4022 - val_acc: 0.1658\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3053 - acc: 0.2360 - val_loss: 2.3223 - val_acc: 0.2342\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.2941 - acc: 0.2518 - val_loss: 2.3416 - val_acc: 0.2289\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.2653 - acc: 0.2582 - val_loss: 2.3173 - val_acc: 0.2289\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.2666 - acc: 0.2623 - val_loss: 2.3099 - val_acc: 0.2079\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2363 - acc: 0.2699 - val_loss: 2.2871 - val_acc: 0.2632\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.1940 - acc: 0.2819 - val_loss: 2.2535 - val_acc: 0.2632\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.1759 - acc: 0.2959 - val_loss: 2.2121 - val_acc: 0.2684\n",
      "950/950 [==============================] - 2s 2ms/sample - loss: 2.2487 - acc: 0.2768 1s - loss: 2.2\n",
      "\n",
      "FOLD-1: Loss=2.248716845261423 , Accuracy=0.2768421173095703\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5719 - acc: 0.1202 - val_loss: 2.5427 - val_acc: 0.1395\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5334 - acc: 0.1377 - val_loss: 2.5415 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5233 - acc: 0.1401 - val_loss: 2.5326 - val_acc: 0.1447\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5166 - acc: 0.1365 - val_loss: 2.5280 - val_acc: 0.1447\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5110 - acc: 0.1626 - val_loss: 2.5219 - val_acc: 0.1368\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5018 - acc: 0.1450 - val_loss: 2.5129 - val_acc: 0.1263\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4876 - acc: 0.1605 - val_loss: 2.4991 - val_acc: 0.1395\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4738 - acc: 0.1652 - val_loss: 2.4856 - val_acc: 0.1421\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4608 - acc: 0.1670 - val_loss: 2.4763 - val_acc: 0.1474\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4501 - acc: 0.1749 - val_loss: 2.4706 - val_acc: 0.1342\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4425 - acc: 0.1754 - val_loss: 2.4529 - val_acc: 0.1737\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4313 - acc: 0.1968 - val_loss: 2.4491 - val_acc: 0.1763\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4319 - acc: 0.1942 - val_loss: 2.4524 - val_acc: 0.1737\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.4212 - acc: 0.1898 - val_loss: 2.4377 - val_acc: 0.1816\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4156 - acc: 0.2029 - val_loss: 2.4261 - val_acc: 0.1789\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4046 - acc: 0.2003 - val_loss: 2.4206 - val_acc: 0.1842\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4052 - acc: 0.1982 - val_loss: 2.4244 - val_acc: 0.1816\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.3945 - acc: 0.2091 - val_loss: 2.4152 - val_acc: 0.1632\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3902 - acc: 0.2041 - val_loss: 2.4179 - val_acc: 0.1684\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.3765 - acc: 0.2064 - val_loss: 2.4080 - val_acc: 0.1789\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3823 - acc: 0.2067 - val_loss: 2.3920 - val_acc: 0.1921\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 11s 3ms/sample - loss: 2.3710 - acc: 0.2208 - val_loss: 2.3816 - val_acc: 0.1737\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.3486 - acc: 0.2222 - val_loss: 2.3650 - val_acc: 0.1895\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.3306 - acc: 0.2392 - val_loss: 2.3679 - val_acc: 0.2368\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3290 - acc: 0.2433 - val_loss: 2.3588 - val_acc: 0.2105\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.3132 - acc: 0.2480 - val_loss: 2.3371 - val_acc: 0.2447\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.2898 - acc: 0.2567 - val_loss: 2.3055 - val_acc: 0.2316\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.2740 - acc: 0.2711 - val_loss: 2.2974 - val_acc: 0.2421\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.2717 - acc: 0.2573 - val_loss: 2.3431 - val_acc: 0.2079\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2627 - acc: 0.2722 - val_loss: 2.3460 - val_acc: 0.1974\n",
      "950/950 [==============================] - 1s 731us/sample - loss: 2.3229 - acc: 0.2126\n",
      "\n",
      "FOLD-2: Loss=2.3229141902923582 , Accuracy=0.21263158321380615\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.5659 - acc: 0.1240 - val_loss: 2.5590 - val_acc: 0.1289\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5300 - acc: 0.1424 - val_loss: 2.5350 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.5232 - acc: 0.1336 - val_loss: 2.5317 - val_acc: 0.1368\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.5160 - acc: 0.1494 - val_loss: 2.5242 - val_acc: 0.1342\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.5089 - acc: 0.1635 - val_loss: 2.5170 - val_acc: 0.1368\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4986 - acc: 0.1579 - val_loss: 2.5071 - val_acc: 0.1316\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4873 - acc: 0.1553 - val_loss: 2.4943 - val_acc: 0.1368\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4748 - acc: 0.1623 - val_loss: 2.4853 - val_acc: 0.1342\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4665 - acc: 0.1550 - val_loss: 2.4780 - val_acc: 0.1211\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4577 - acc: 0.1602 - val_loss: 2.4641 - val_acc: 0.1342\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4481 - acc: 0.1673 - val_loss: 2.4588 - val_acc: 0.1421\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4438 - acc: 0.1591 - val_loss: 2.4586 - val_acc: 0.1368\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4435 - acc: 0.1635 - val_loss: 2.4536 - val_acc: 0.1816\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4309 - acc: 0.1743 - val_loss: 2.4471 - val_acc: 0.1395\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4269 - acc: 0.1822 - val_loss: 2.4364 - val_acc: 0.1447\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4173 - acc: 0.1857 - val_loss: 2.4355 - val_acc: 0.1842\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4028 - acc: 0.1997 - val_loss: 2.4293 - val_acc: 0.1842\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4004 - acc: 0.1933 - val_loss: 2.4215 - val_acc: 0.1474\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.3943 - acc: 0.1977 - val_loss: 2.4465 - val_acc: 0.1553\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3843 - acc: 0.2076 - val_loss: 2.3958 - val_acc: 0.1737\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3650 - acc: 0.2012 - val_loss: 2.3912 - val_acc: 0.1684\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3660 - acc: 0.2067 - val_loss: 2.3877 - val_acc: 0.1974\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3600 - acc: 0.2099 - val_loss: 2.3706 - val_acc: 0.2026\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3432 - acc: 0.2187 - val_loss: 2.3582 - val_acc: 0.2079\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3389 - acc: 0.2190 - val_loss: 2.3720 - val_acc: 0.2263\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3328 - acc: 0.2336 - val_loss: 2.3765 - val_acc: 0.1947\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3067 - acc: 0.2368 - val_loss: 2.3379 - val_acc: 0.2079\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2799 - acc: 0.2538 - val_loss: 2.3778 - val_acc: 0.1868\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2761 - acc: 0.2556 - val_loss: 2.2944 - val_acc: 0.2368\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2710 - acc: 0.2561 - val_loss: 2.3160 - val_acc: 0.2395\n",
      "950/950 [==============================] - 1s 613us/sample - loss: 2.3128 - acc: 0.2516\n",
      "\n",
      "FOLD-3: Loss=2.3128379786641973 , Accuracy=0.2515789568424225\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.5728 - acc: 0.1213 - val_loss: 2.5595 - val_acc: 0.1342\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5320 - acc: 0.1482 - val_loss: 2.5357 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5168 - acc: 0.1442 - val_loss: 2.5329 - val_acc: 0.1237\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.5078 - acc: 0.1556 - val_loss: 2.5197 - val_acc: 0.1500\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4947 - acc: 0.1579 - val_loss: 2.5134 - val_acc: 0.1526\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4864 - acc: 0.1675 - val_loss: 2.5006 - val_acc: 0.1289\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4792 - acc: 0.1582 - val_loss: 2.4913 - val_acc: 0.1526\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4630 - acc: 0.1787 - val_loss: 2.4977 - val_acc: 0.1447\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4600 - acc: 0.1708 - val_loss: 2.4770 - val_acc: 0.1553\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4474 - acc: 0.1851 - val_loss: 2.4733 - val_acc: 0.1395\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4427 - acc: 0.1769 - val_loss: 2.4653 - val_acc: 0.1658\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4345 - acc: 0.1836 - val_loss: 2.4540 - val_acc: 0.1684\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4280 - acc: 0.1909 - val_loss: 2.4509 - val_acc: 0.1658\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4187 - acc: 0.1883 - val_loss: 2.4391 - val_acc: 0.1632\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4121 - acc: 0.1915 - val_loss: 2.4501 - val_acc: 0.1579\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.3983 - acc: 0.1933 - val_loss: 2.4181 - val_acc: 0.1789\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3855 - acc: 0.2035 - val_loss: 2.4125 - val_acc: 0.1711\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.3847 - acc: 0.2047 - val_loss: 2.4008 - val_acc: 0.1658\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3613 - acc: 0.2085 - val_loss: 2.3874 - val_acc: 0.1921\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.3526 - acc: 0.2143 - val_loss: 2.4151 - val_acc: 0.1737\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.3381 - acc: 0.2251 - val_loss: 2.3692 - val_acc: 0.1737\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3216 - acc: 0.2363 - val_loss: 2.3717 - val_acc: 0.2026\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3386 - acc: 0.2196 - val_loss: 2.4149 - val_acc: 0.1579\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.3707 - acc: 0.2102 - val_loss: 2.3897 - val_acc: 0.2184\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.3308 - acc: 0.2316 - val_loss: 2.3868 - val_acc: 0.1763\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2876 - acc: 0.2368 - val_loss: 2.3057 - val_acc: 0.2211\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2850 - acc: 0.2442 - val_loss: 2.3393 - val_acc: 0.2237\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2871 - acc: 0.2485 - val_loss: 2.2920 - val_acc: 0.2658\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2290 - acc: 0.2760 - val_loss: 2.2709 - val_acc: 0.2579\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2039 - acc: 0.2842 - val_loss: 2.2733 - val_acc: 0.2342\n",
      "950/950 [==============================] - 1s 623us/sample - loss: 2.2962 - acc: 0.2274\n",
      "\n",
      "FOLD-4: Loss=2.296236235969945 , Accuracy=0.22736841440200806\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.5701 - acc: 0.1216 - val_loss: 2.5314 - val_acc: 0.1211\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.5309 - acc: 0.1389 - val_loss: 2.5188 - val_acc: 0.1211\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5276 - acc: 0.1389 - val_loss: 2.5160 - val_acc: 0.1368\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5244 - acc: 0.1485 - val_loss: 2.5156 - val_acc: 0.1553\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 2.5213 - acc: 0.1380 - val_loss: 2.5117 - val_acc: 0.1684\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5173 - acc: 0.1538 - val_loss: 2.5100 - val_acc: 0.1711\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5135 - acc: 0.1509 - val_loss: 2.5043 - val_acc: 0.1737\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.5067 - acc: 0.1608 - val_loss: 2.4980 - val_acc: 0.1816\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4986 - acc: 0.1547 - val_loss: 2.4914 - val_acc: 0.1816\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4873 - acc: 0.1658 - val_loss: 2.4839 - val_acc: 0.1842\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4765 - acc: 0.1670 - val_loss: 2.4707 - val_acc: 0.1763\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4647 - acc: 0.1632 - val_loss: 2.4655 - val_acc: 0.1737\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 2.4559 - acc: 0.1772 - val_loss: 2.4439 - val_acc: 0.1947\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4470 - acc: 0.1839 - val_loss: 2.4355 - val_acc: 0.1842\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4385 - acc: 0.1906 - val_loss: 2.4311 - val_acc: 0.1711\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4322 - acc: 0.1860 - val_loss: 2.4211 - val_acc: 0.1868\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4263 - acc: 0.1915 - val_loss: 2.4272 - val_acc: 0.1421\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4216 - acc: 0.1880 - val_loss: 2.4094 - val_acc: 0.1737\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4049 - acc: 0.2023 - val_loss: 2.3962 - val_acc: 0.2105\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4018 - acc: 0.2041 - val_loss: 2.3942 - val_acc: 0.2395\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3923 - acc: 0.2035 - val_loss: 2.3749 - val_acc: 0.2395\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3779 - acc: 0.2222 - val_loss: 2.3787 - val_acc: 0.1895\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3632 - acc: 0.2178 - val_loss: 2.3771 - val_acc: 0.2079\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3571 - acc: 0.2263 - val_loss: 2.3655 - val_acc: 0.2053\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3445 - acc: 0.2240 - val_loss: 2.3425 - val_acc: 0.2263\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3188 - acc: 0.2538 - val_loss: 2.3401 - val_acc: 0.2158\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3252 - acc: 0.2351 - val_loss: 2.3359 - val_acc: 0.2632\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2950 - acc: 0.2591 - val_loss: 2.3356 - val_acc: 0.2342\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3062 - acc: 0.2474 - val_loss: 2.3334 - val_acc: 0.2184\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2696 - acc: 0.2614 - val_loss: 2.2761 - val_acc: 0.2842\n",
      "950/950 [==============================] - 1s 609us/sample - loss: 2.2926 - acc: 0.2484\n",
      "\n",
      "FOLD-5: Loss=2.292616173091688 , Accuracy=0.2484210580587387\n",
      "\n",
      "\n",
      "Average Accuracy : 0.2434\n",
      "\n",
      "Execution Time\t : 1066.6562s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# initializing variables for kFold run and average accuracy\n",
    "current_fold = 0\n",
    "sum_acc = 0\n",
    "avg_acc = 0\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "for train_index, test_index in KFold(N_SPLIT).split(X):\n",
    "    current_fold += 1\n",
    "    \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    \n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT, callbacks=[tensorboard])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"\\nFOLD-{current_fold}: Loss={val_loss} , Accuracy={val_acc}\\n\")\n",
    "    \n",
    "    sum_acc += val_acc \n",
    "    file.write(f\"{current_fold}-FOLD | Loss={round(val_loss,4)},\\tAccuracy={round(val_acc,4)},\\tAverage_Accuracy={round(sum_acc/current_fold,4)}\\n\")\n",
    "    \n",
    "    if(current_fold == N_SPLIT):\n",
    "        avg_acc = round(sum_acc/current_fold,4)\n",
    "    \n",
    "\n",
    "avg_acc_line = f\"\\nAverage Accuracy : {round(avg_acc,4)}\"\n",
    "\n",
    "end = time.process_time()\n",
    "time_taken = f\"\\nExecution Time\\t : {round(end-start,4)}s\"\n",
    "\n",
    "print(avg_acc_line)\n",
    "print(time_taken)\n",
    "\n",
    "file.write(avg_acc_line)\n",
    "file.write(time_taken)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{REPORT_NAME}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 58, 58, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 904,812\n",
      "Trainable params: 904,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To reset GPU memory after model training. But seems this doesn't work. Always need to restart the kernel and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow-gpu-1-13)",
   "language": "python",
   "name": "tensorflow-gpu-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
