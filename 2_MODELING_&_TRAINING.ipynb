{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Specifing run configurations and regularization constants. These are used to tweak the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CONFIGURATIONS\n",
    "TEST = 10\n",
    "CNN_ACT_F = \"relu\"\n",
    "DNS_ACT_F = \"tanh\"\n",
    "ARCH = f\"CNN(64,128,256)_{CNN_ACT_F}_DENSE(128,64,32,12)_{DNS_ACT_F}\"\n",
    "IMG_SIZE = 50\n",
    "N_SPLIT = 5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 50\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "\n",
    "# REGULARIZATIONS\n",
    "DROPOUT_RATE = 0.3\n",
    "LAMBDA_1 = 1e-6\n",
    "LAMBDA_2 = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(f\"X_{IMG_SIZE}.pickle\", \"rb\"))\n",
    "Y = pickle.load(open(f\"Y_{IMG_SIZE}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating the report name for the corresponding tweak of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 - CNN(64,128,256)_relu_DENSE(128,64,32,12)_tanh - 50px_30e_50bs_10vs_REG_30do_1L1_1L2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPORT_NAME = f\"{TEST} - {ARCH} - {IMG_SIZE}px_{EPOCHS}e_{BATCH_SIZE}bs_{int(VAL_SPLIT*100)}vs_REG_{int(DROPOUT_RATE*100)}do_{int(LAMBDA_1*1000000)}L1_{int(LAMBDA_2*1000000)}L2\"\n",
    "REPORT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing tensorflow-gpu and other related libs and classes. Tensorboard is used to see live tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"NN_GA_CNN_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{MODEL_NAME}\")\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), input_shape=(IMG_SIZE,IMG_SIZE,1)))  # input shape is IMG_SIZExIMG_SIZEx1\n",
    "#     model.add(BatchNormalization(axis=3))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3)))\n",
    "    model.add(Activation(CNN_ACT_F))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(128, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3,3)))\n",
    "#     model.add(Activation(CNN_ACT_F))\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(rate=DROPOUT_RATE))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128))\n",
    "    model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=LAMBDA_1, l2=LAMBDA_2)))\n",
    "    model.add(Activation(DNS_ACT_F))\n",
    "    \n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating folder for saving reports of the model executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('reports'):\n",
    "    os.makedirs('reports')\n",
    "\n",
    "file = open(f\"reports/{REPORT_NAME}.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Designed the 5-fold cross validation training and test with specific validation split. Final accuracy is averaged by the accuracies of the separate 5 folds. Time taken for the execution is also measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Thilina\\.conda\\envs\\tensorflow-gpu-1-13\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 8s 2ms/sample - loss: 2.4312 - acc: 0.1357 - val_loss: 2.4798 - val_acc: 0.1158\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3977 - acc: 0.1523 - val_loss: 2.4466 - val_acc: 0.1711\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3770 - acc: 0.1599 - val_loss: 2.4393 - val_acc: 0.1500\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3727 - acc: 0.1564 - val_loss: 2.4541 - val_acc: 0.1447\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3541 - acc: 0.1614 - val_loss: 2.4269 - val_acc: 0.1553\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3408 - acc: 0.1667 - val_loss: 2.4122 - val_acc: 0.1553\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3245 - acc: 0.1763 - val_loss: 2.4012 - val_acc: 0.1842\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2885 - acc: 0.2035 - val_loss: 2.3905 - val_acc: 0.1658\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2480 - acc: 0.2257 - val_loss: 2.3512 - val_acc: 0.2026\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2228 - acc: 0.2339 - val_loss: 2.3124 - val_acc: 0.1974\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1526 - acc: 0.2573 - val_loss: 2.3186 - val_acc: 0.2026\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0993 - acc: 0.2705 - val_loss: 2.2433 - val_acc: 0.2395\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0285 - acc: 0.3015 - val_loss: 2.2162 - val_acc: 0.2395\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.9114 - acc: 0.3401 - val_loss: 2.0822 - val_acc: 0.3000\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.7634 - acc: 0.4047 - val_loss: 1.9652 - val_acc: 0.3711\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.6719 - acc: 0.4292 - val_loss: 2.0769 - val_acc: 0.3184\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5650 - acc: 0.4673 - val_loss: 1.8845 - val_acc: 0.3868\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5206 - acc: 0.4842 - val_loss: 1.8260 - val_acc: 0.4211\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.3349 - acc: 0.5512 - val_loss: 1.6771 - val_acc: 0.4447\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2236 - acc: 0.5819 - val_loss: 1.5493 - val_acc: 0.4921\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2248 - acc: 0.5904 - val_loss: 1.6970 - val_acc: 0.4368\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1056 - acc: 0.6254 - val_loss: 1.6553 - val_acc: 0.4868\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9589 - acc: 0.6863 - val_loss: 1.5626 - val_acc: 0.4921\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.8525 - acc: 0.7143 - val_loss: 1.5426 - val_acc: 0.4974\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.8468 - acc: 0.7108 - val_loss: 1.7767 - val_acc: 0.4079\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7729 - acc: 0.7389 - val_loss: 1.5712 - val_acc: 0.4789\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6571 - acc: 0.7915 - val_loss: 1.5742 - val_acc: 0.5447\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.5220 - acc: 0.8313 - val_loss: 1.4389 - val_acc: 0.5711\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4378 - acc: 0.8751 - val_loss: 1.5314 - val_acc: 0.5553\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4440 - acc: 0.8637 - val_loss: 1.6615 - val_acc: 0.5158\n",
      "950/950 [==============================] - 1s 610us/sample - loss: 1.5277 - acc: 0.5621\n",
      "\n",
      "FOLD-1: Loss=1.527745852721365 , Accuracy=0.5621052384376526\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4317 - acc: 0.1231 - val_loss: 2.4707 - val_acc: 0.1132\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3982 - acc: 0.1421 - val_loss: 2.4796 - val_acc: 0.1447\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3605 - acc: 0.1541 - val_loss: 2.4735 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3510 - acc: 0.1561 - val_loss: 2.4914 - val_acc: 0.1342\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3322 - acc: 0.1731 - val_loss: 2.4753 - val_acc: 0.1368\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3432 - acc: 0.1623 - val_loss: 2.4412 - val_acc: 0.1579\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3156 - acc: 0.1842 - val_loss: 2.4324 - val_acc: 0.1500\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3149 - acc: 0.1766 - val_loss: 2.4326 - val_acc: 0.1500\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2952 - acc: 0.1927 - val_loss: 2.4340 - val_acc: 0.1658\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2514 - acc: 0.2161 - val_loss: 2.3724 - val_acc: 0.1868\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1875 - acc: 0.2442 - val_loss: 2.4029 - val_acc: 0.1579\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1660 - acc: 0.2421 - val_loss: 2.2807 - val_acc: 0.2421\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0872 - acc: 0.2751 - val_loss: 2.2865 - val_acc: 0.2158\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0129 - acc: 0.3050 - val_loss: 2.2602 - val_acc: 0.2658\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.8947 - acc: 0.3520 - val_loss: 2.0609 - val_acc: 0.2921\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.7534 - acc: 0.4222 - val_loss: 2.3330 - val_acc: 0.2579\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.8090 - acc: 0.3854 - val_loss: 2.1818 - val_acc: 0.2447\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.6109 - acc: 0.4497 - val_loss: 1.8369 - val_acc: 0.4053\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5032 - acc: 0.4968 - val_loss: 1.7386 - val_acc: 0.4237\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.3567 - acc: 0.5415 - val_loss: 1.6557 - val_acc: 0.4368\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.3083 - acc: 0.5512 - val_loss: 1.7583 - val_acc: 0.3763\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2181 - acc: 0.5930 - val_loss: 1.5625 - val_acc: 0.4895\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1580 - acc: 0.6164 - val_loss: 1.7293 - val_acc: 0.4105\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.0742 - acc: 0.6325 - val_loss: 1.5585 - val_acc: 0.4895\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9503 - acc: 0.6795 - val_loss: 1.4740 - val_acc: 0.5289\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9208 - acc: 0.6865 - val_loss: 1.6049 - val_acc: 0.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7945 - acc: 0.7357 - val_loss: 1.4202 - val_acc: 0.5289\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7279 - acc: 0.7637 - val_loss: 1.3939 - val_acc: 0.5447\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6062 - acc: 0.8003 - val_loss: 1.4731 - val_acc: 0.5474\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.5235 - acc: 0.8368 - val_loss: 1.3492 - val_acc: 0.5605\n",
      "950/950 [==============================] - 1s 538us/sample - loss: 1.3426 - acc: 0.5811\n",
      "\n",
      "FOLD-2: Loss=1.3426102483899969 , Accuracy=0.5810526609420776\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4398 - acc: 0.1266 - val_loss: 2.4614 - val_acc: 0.1447\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.4127 - acc: 0.1433 - val_loss: 2.4579 - val_acc: 0.1211\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3930 - acc: 0.1515 - val_loss: 2.4821 - val_acc: 0.1132\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3663 - acc: 0.1570 - val_loss: 2.4526 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3389 - acc: 0.1746 - val_loss: 2.4283 - val_acc: 0.1763\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3231 - acc: 0.1757 - val_loss: 2.4323 - val_acc: 0.1395\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3120 - acc: 0.1880 - val_loss: 2.4371 - val_acc: 0.1553\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2885 - acc: 0.2006 - val_loss: 2.3932 - val_acc: 0.1895\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2506 - acc: 0.2219 - val_loss: 2.3211 - val_acc: 0.2026\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2241 - acc: 0.2336 - val_loss: 2.3744 - val_acc: 0.1605\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1773 - acc: 0.2439 - val_loss: 2.2894 - val_acc: 0.2237\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1193 - acc: 0.2661 - val_loss: 2.2367 - val_acc: 0.2368\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0229 - acc: 0.3143 - val_loss: 2.2165 - val_acc: 0.2316\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.9107 - acc: 0.3535 - val_loss: 2.1890 - val_acc: 0.2737\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.8008 - acc: 0.3868 - val_loss: 2.1910 - val_acc: 0.2763\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.6574 - acc: 0.4339 - val_loss: 1.8156 - val_acc: 0.4105\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5704 - acc: 0.4690 - val_loss: 1.7849 - val_acc: 0.3947\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5596 - acc: 0.4711 - val_loss: 1.7901 - val_acc: 0.4000\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.3913 - acc: 0.5184 - val_loss: 1.6835 - val_acc: 0.4605\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2912 - acc: 0.5652 - val_loss: 1.7568 - val_acc: 0.4184\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1653 - acc: 0.6105 - val_loss: 1.5735 - val_acc: 0.4684\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.0835 - acc: 0.6301 - val_loss: 1.6525 - val_acc: 0.4763\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.0507 - acc: 0.6418 - val_loss: 1.5670 - val_acc: 0.5105\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9986 - acc: 0.6576 - val_loss: 1.4531 - val_acc: 0.5316\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9092 - acc: 0.6892 - val_loss: 1.4238 - val_acc: 0.5184\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7471 - acc: 0.7591 - val_loss: 1.5457 - val_acc: 0.5158\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6191 - acc: 0.8053 - val_loss: 1.4430 - val_acc: 0.5395\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6028 - acc: 0.8020 - val_loss: 1.5552 - val_acc: 0.5263\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.5721 - acc: 0.8187 - val_loss: 1.5642 - val_acc: 0.5342\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4335 - acc: 0.8699 - val_loss: 1.4994 - val_acc: 0.5658\n",
      "950/950 [==============================] - 1s 541us/sample - loss: 1.4290 - acc: 0.5653\n",
      "\n",
      "FOLD-3: Loss=1.4290018134368094 , Accuracy=0.5652631521224976\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 1ms/sample - loss: 2.4305 - acc: 0.1310 - val_loss: 2.4543 - val_acc: 0.1500\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3780 - acc: 0.1509 - val_loss: 2.4877 - val_acc: 0.1263\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3820 - acc: 0.1547 - val_loss: 2.4638 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3545 - acc: 0.1640 - val_loss: 2.4671 - val_acc: 0.1237\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3271 - acc: 0.1775 - val_loss: 2.4340 - val_acc: 0.1711\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3508 - acc: 0.1614 - val_loss: 2.4770 - val_acc: 0.1342\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3077 - acc: 0.1936 - val_loss: 2.3988 - val_acc: 0.1684\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2794 - acc: 0.1982 - val_loss: 2.3614 - val_acc: 0.1789\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2295 - acc: 0.2173 - val_loss: 2.3626 - val_acc: 0.1763\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2178 - acc: 0.2275 - val_loss: 2.3252 - val_acc: 0.2026\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1629 - acc: 0.2582 - val_loss: 2.3019 - val_acc: 0.2184\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1261 - acc: 0.2646 - val_loss: 2.2178 - val_acc: 0.2553\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0194 - acc: 0.3158 - val_loss: 2.1708 - val_acc: 0.2447\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.9214 - acc: 0.3553 - val_loss: 2.1805 - val_acc: 0.2500\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.8226 - acc: 0.3860 - val_loss: 2.1740 - val_acc: 0.3053\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.7140 - acc: 0.4251 - val_loss: 1.9206 - val_acc: 0.3500\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5857 - acc: 0.4675 - val_loss: 1.7687 - val_acc: 0.4079\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5100 - acc: 0.4971 - val_loss: 1.8416 - val_acc: 0.4000\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.4422 - acc: 0.5181 - val_loss: 1.6636 - val_acc: 0.4500\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2939 - acc: 0.5585 - val_loss: 1.6766 - val_acc: 0.4184\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2001 - acc: 0.5942 - val_loss: 1.7015 - val_acc: 0.4474\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1402 - acc: 0.6070 - val_loss: 1.8238 - val_acc: 0.3763\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.0340 - acc: 0.6526 - val_loss: 1.6462 - val_acc: 0.4974\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9353 - acc: 0.6863 - val_loss: 2.0778 - val_acc: 0.3947\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.8738 - acc: 0.7050 - val_loss: 1.5388 - val_acc: 0.5263\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.8105 - acc: 0.7310 - val_loss: 1.5672 - val_acc: 0.5079\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7307 - acc: 0.7591 - val_loss: 1.4864 - val_acc: 0.5316\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6049 - acc: 0.8058 - val_loss: 1.5674 - val_acc: 0.5316\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4900 - acc: 0.8541 - val_loss: 1.5709 - val_acc: 0.5868\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4067 - acc: 0.8787 - val_loss: 1.6260 - val_acc: 0.5316\n",
      "950/950 [==============================] - 1s 593us/sample - loss: 1.5178 - acc: 0.5358\n",
      "\n",
      "FOLD-4: Loss=1.517762599493328 , Accuracy=0.5357894897460938\n",
      "\n",
      "Train on 3420 samples, validate on 380 samples\n",
      "Epoch 1/30\n",
      "3420/3420 [==============================] - 5s 2ms/sample - loss: 2.4339 - acc: 0.1442 - val_loss: 2.4157 - val_acc: 0.1158\n",
      "Epoch 2/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3956 - acc: 0.1523 - val_loss: 2.3752 - val_acc: 0.1395\n",
      "Epoch 3/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3672 - acc: 0.1550 - val_loss: 2.3868 - val_acc: 0.1500\n",
      "Epoch 4/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3487 - acc: 0.1716 - val_loss: 2.3314 - val_acc: 0.1579\n",
      "Epoch 5/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3215 - acc: 0.1702 - val_loss: 2.3787 - val_acc: 0.1474\n",
      "Epoch 6/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.3435 - acc: 0.1635 - val_loss: 2.3085 - val_acc: 0.1974\n",
      "Epoch 7/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2956 - acc: 0.1889 - val_loss: 2.2843 - val_acc: 0.1842\n",
      "Epoch 8/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2482 - acc: 0.2108 - val_loss: 2.3023 - val_acc: 0.2105\n",
      "Epoch 9/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.2127 - acc: 0.2275 - val_loss: 2.2226 - val_acc: 0.2342\n",
      "Epoch 10/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.1421 - acc: 0.2646 - val_loss: 2.1366 - val_acc: 0.2816\n",
      "Epoch 11/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 2.0672 - acc: 0.3020 - val_loss: 2.1142 - val_acc: 0.2474\n",
      "Epoch 12/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.9640 - acc: 0.3278 - val_loss: 1.9550 - val_acc: 0.3526\n",
      "Epoch 13/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.8259 - acc: 0.3857 - val_loss: 1.8667 - val_acc: 0.3263\n",
      "Epoch 14/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.7062 - acc: 0.4170 - val_loss: 1.7366 - val_acc: 0.4316\n",
      "Epoch 15/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.6186 - acc: 0.4602 - val_loss: 1.7947 - val_acc: 0.3553\n",
      "Epoch 16/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.5053 - acc: 0.4950 - val_loss: 1.6295 - val_acc: 0.4447\n",
      "Epoch 17/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.4257 - acc: 0.5117 - val_loss: 1.7085 - val_acc: 0.4237\n",
      "Epoch 18/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.2626 - acc: 0.5731 - val_loss: 1.5298 - val_acc: 0.4526\n",
      "Epoch 19/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1755 - acc: 0.6050 - val_loss: 1.4289 - val_acc: 0.5421\n",
      "Epoch 20/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.1263 - acc: 0.6184 - val_loss: 1.4920 - val_acc: 0.4842\n",
      "Epoch 21/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.9818 - acc: 0.6646 - val_loss: 1.3542 - val_acc: 0.5579\n",
      "Epoch 22/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 1.0142 - acc: 0.6468 - val_loss: 1.4029 - val_acc: 0.5447\n",
      "Epoch 23/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.8425 - acc: 0.7143 - val_loss: 1.4397 - val_acc: 0.5237\n",
      "Epoch 24/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7121 - acc: 0.7754 - val_loss: 1.5647 - val_acc: 0.4868\n",
      "Epoch 25/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.7398 - acc: 0.7450 - val_loss: 1.4520 - val_acc: 0.5447\n",
      "Epoch 26/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.6152 - acc: 0.8000 - val_loss: 1.3808 - val_acc: 0.5711\n",
      "Epoch 27/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.5160 - acc: 0.8395 - val_loss: 1.6059 - val_acc: 0.5289\n",
      "Epoch 28/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4790 - acc: 0.8471 - val_loss: 1.5738 - val_acc: 0.5421\n",
      "Epoch 29/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.4436 - acc: 0.8570 - val_loss: 1.4891 - val_acc: 0.5474\n",
      "Epoch 30/30\n",
      "3420/3420 [==============================] - 4s 1ms/sample - loss: 0.3186 - acc: 0.9096 - val_loss: 1.6047 - val_acc: 0.5474\n",
      "950/950 [==============================] - 1s 569us/sample - loss: 1.5426 - acc: 0.5453\n",
      "\n",
      "FOLD-5: Loss=1.5426496852071663 , Accuracy=0.5452631711959839\n",
      "\n",
      "\n",
      "Average Accuracy : 0.5579\n",
      "\n",
      "Execution Time\t : 1075.0469s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# initializing variables for kFold run and average accuracy\n",
    "current_fold = 0\n",
    "sum_acc = 0\n",
    "avg_acc = 0\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "for train_index, test_index in KFold(N_SPLIT).split(X):\n",
    "    current_fold += 1\n",
    "    \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    \n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT, callbacks=[tensorboard])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"\\nFOLD-{current_fold}: Loss={val_loss} , Accuracy={val_acc}\\n\")\n",
    "    \n",
    "    sum_acc += val_acc \n",
    "    file.write(f\"{current_fold}-FOLD | Loss={round(val_loss,4)},\\tAccuracy={round(val_acc,4)},\\tAverage_Accuracy={round(sum_acc/current_fold,4)}\\n\")\n",
    "    \n",
    "    if(current_fold == N_SPLIT):\n",
    "        avg_acc = round(sum_acc/current_fold,4)\n",
    "    \n",
    "\n",
    "avg_acc_line = f\"\\nAverage Accuracy : {round(avg_acc,4)}\"\n",
    "\n",
    "end = time.process_time()\n",
    "time_taken = f\"\\nExecution Time\\t : {round(end-start,4)}s\"\n",
    "\n",
    "print(avg_acc_line)\n",
    "print(time_taken)\n",
    "\n",
    "file.write(avg_acc_line)\n",
    "file.write(time_taken)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{REPORT_NAME}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 675,436\n",
      "Trainable params: 675,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To reset GPU memory after model training. But seems this doesn't work. Always need to restart the kernel and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow-gpu-1-13)",
   "language": "python",
   "name": "tensorflow-gpu-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
